import streamlit as st
import pandas as pd
import re
import io

# -----------------------------------------------------------------------------
# 1. ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# -----------------------------------------------------------------------------

def load_data(uploaded_file):
    """íŒŒì¼ ë¡œë“œ (CSV, Excel)"""
    file_ext = uploaded_file.name.split('.')[-1].lower()
    try:
        if file_ext == 'csv':
            return pd.read_csv(uploaded_file, header=None)
        elif file_ext in ['xlsx', 'xls']:
            return pd.read_excel(uploaded_file, header=None, engine='openpyxl')
        else:
            return None
    except Exception as e:
        st.error(f"íŒŒì¼ ì˜¤ë¥˜ ({uploaded_file.name}): {e}")
        return None

def extract_grade_class(df_raw):
    """í•™ë…„ ë°˜ ì¶”ì¶œ"""
    limit = min(20, len(df_raw))
    for i in range(limit):
        row_values = df_raw.iloc[i].astype(str).values
        for val in row_values:
            match = re.search(r"(\d+)í•™ë…„\s*(\d+)ë°˜", val)
            if match:
                return match.group(0)
    return "ë¯¸ìƒ"

def detect_file_type(df_raw):
    """íŒŒì¼ ìœ í˜• ê°ì§€ (í–‰íŠ¹ / ì„¸íŠ¹ / ì°½ì²´)"""
    limit = min(20, len(df_raw))
    text_sample = df_raw.iloc[:limit].astype(str).to_string()
    
    if "ì°½ì˜ì " in text_sample and ("ì²´í—˜í™œë™" in text_sample or "ììœ¨" in text_sample):
        return "CHANG" # ì°½ì˜ì  ì²´í—˜í™œë™
    elif "í–‰ ë™ íŠ¹ ì„±" in text_sample or "í–‰ë™íŠ¹ì„±" in text_sample or "ì¢…í•©ì˜ê²¬" in text_sample:
        return "HANG" # í–‰ë™íŠ¹ì„±
    elif "ì„¸ë¶€ëŠ¥ë ¥" in text_sample or "íŠ¹ê¸°ì‚¬í•­" in text_sample or "ê³¼ ëª©" in text_sample:
        return "KYO" # ì„¸ë¶€ëŠ¥ë ¥(êµê³¼)
    else:
        return "UNKNOWN"

# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ì²˜ë¦¬ ë¡œì§ (í–‰íŠ¹ / ì„¸íŠ¹ / ì°½ì²´)
# -----------------------------------------------------------------------------

def process_hang(df_raw, grade_class):
    """í–‰ë™íŠ¹ì„± ì²˜ë¦¬"""
    # í—¤ë” ì°¾ê¸°
    header_idx = -1
    for i, row in df_raw.iterrows():
        row_str = row.astype(str).values
        if any('ë²ˆ' in s and 'í˜¸' in s for s in row_str) and any('ì„±' in s and 'ëª…' in s for s in row_str):
            header_idx = i
            break
    
    if header_idx == -1: return None

    df = df_raw.iloc[header_idx+1:].copy()
    df.columns = df_raw.iloc[header_idx].astype(str).str.replace(" ", "")
    
    # ì»¬ëŸ¼ ë§¤í•‘
    rename_map = {}
    for col in df.columns:
        if 'ë²ˆí˜¸' in col: rename_map[col] = 'ë²ˆí˜¸'
        elif 'í–‰ë™íŠ¹ì„±' in col: rename_map[col] = 'ë‚´ìš©'
        elif 'ì¢…í•©ì˜ê²¬' in col: rename_map[col] = 'ë‚´ìš©'
    df = df.rename(columns=rename_map)
    
    if 'ë²ˆí˜¸' not in df.columns or 'ë‚´ìš©' not in df.columns: return None
        
    df['ë²ˆí˜¸'] = pd.to_numeric(df['ë²ˆí˜¸'], errors='coerce')
    df = df[df['ë‚´ìš©'].notna()]
    df = df[~df['ë‚´ìš©'].str.contains('í–‰ ë™ íŠ¹ ì„±', na=False)]
    df = df[~df['ë‚´ìš©'].str.contains('ì¢… í•© ì˜ ê²¬', na=False)]
    
    df['ë²ˆí˜¸'] = df['ë²ˆí˜¸'].ffill()
    df = df.dropna(subset=['ë²ˆí˜¸'])
    
    df_grouped = df.groupby('ë²ˆí˜¸')['ë‚´ìš©'].apply(lambda x: ' '.join(x.astype(str))).reset_index()
    
    # ìµœì¢… í¬ë§· ë§ì¶”ê¸°
    df_grouped['í•™ë…„ ë°˜'] = grade_class
    df_grouped['í•™ê¸°'] = ''
    df_grouped['ê³¼ëª©/ì˜ì—­'] = 'í–‰ë™íŠ¹ì„±'
    df_grouped['ì‹œìˆ˜'] = '' # í–‰íŠ¹ì€ ì‹œìˆ˜ ì—†ìŒ
    
    return df_grouped[['í•™ë…„ ë°˜', 'ë²ˆí˜¸', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­', 'ì‹œìˆ˜', 'ë‚´ìš©']]

def process_kyo(df_raw, grade_class):
    """ì„¸ë¶€ëŠ¥ë ¥(êµê³¼) ì²˜ë¦¬"""
    header_idx = -1
    for i, row in df_raw.iterrows():
        row_str = row.astype(str).values
        if any('ê³¼' in s and 'ëª©' in s for s in row_str) and any('ì„¸ë¶€ëŠ¥ë ¥' in s for s in row_str):
            header_idx = i
            break
            
    if header_idx == -1: return None
        
    df = df_raw.iloc[header_idx+1:].copy()
    df.columns = df_raw.iloc[header_idx].astype(str).str.replace(" ", "")
    
    rename_map = {}
    for col in df.columns:
        if 'ê³¼ëª©' in col: rename_map[col] = 'ê³¼ëª©/ì˜ì—­'
        elif 'í•™ê¸°' in col: rename_map[col] = 'í•™ê¸°'
        elif 'ë²ˆí˜¸' in col: rename_map[col] = 'ë²ˆí˜¸'
        elif 'ì„¸ë¶€ëŠ¥ë ¥' in col: rename_map[col] = 'ë‚´ìš©'
        elif 'íŠ¹ê¸°ì‚¬í•­' in col: rename_map[col] = 'ë‚´ìš©'
    df = df.rename(columns=rename_map)
    
    if 'ë‚´ìš©' not in df.columns or 'ê³¼ëª©/ì˜ì—­' not in df.columns: return None

    df['ë²ˆí˜¸'] = pd.to_numeric(df['ë²ˆí˜¸'], errors='coerce')
    
    # ë¶ˆí•„ìš”í•œ í–‰ ì œê±°
    df = df[df['ê³¼ëª©/ì˜ì—­'] != 'ê³¼ ëª©']
    df = df[df['ê³¼ëª©/ì˜ì—­'] != 'ê³¼ëª©']
    
    # ê°’ ì±„ìš°ê¸°
    df['ë²ˆí˜¸'] = df['ë²ˆí˜¸'].ffill()
    df['ê³¼ëª©/ì˜ì—­'] = df['ê³¼ëª©/ì˜ì—­'].ffill()
    df['í•™ê¸°'] = df['í•™ê¸°'].ffill()
    
    df = df.dropna(subset=['ë²ˆí˜¸', 'ë‚´ìš©'])
    
    df_grouped = df.groupby(['ë²ˆí˜¸', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­'])['ë‚´ìš©'].apply(lambda x: ' '.join(x.astype(str))).reset_index()
    
    # ìµœì¢… í¬ë§·
    df_grouped['í•™ë…„ ë°˜'] = grade_class
    df_grouped['ì‹œìˆ˜'] = '' # ì„¸íŠ¹ì€ ì‹œìˆ˜ ì—†ìŒ
    
    return df_grouped[['í•™ë…„ ë°˜', 'ë²ˆí˜¸', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­', 'ì‹œìˆ˜', 'ë‚´ìš©']]

def process_chang(df_raw, grade_class):
    """ì°½ì˜ì  ì²´í—˜í™œë™(ììœ¨/ì§„ë¡œ) ì²˜ë¦¬"""
    header_idx = -1
    for i, row in df_raw.iterrows():
        row_str = row.astype(str).values
        # 'ì˜ ì—­'ê³¼ 'ì‹œ ê°„'ì´ í¬í•¨ëœ í—¤ë” ì°¾ê¸°
        if any('ì˜' in s and 'ì—­' in s for s in row_str) and any('ì‹œ' in s and 'ê°„' in s for s in row_str):
            header_idx = i
            break
            
    if header_idx == -1: return None
        
    df = df_raw.iloc[header_idx+1:].copy()
    df.columns = df_raw.iloc[header_idx].astype(str).str.replace(" ", "")
    
    # ì»¬ëŸ¼ ë§¤í•‘ (ì°½ì²´ íŠ¹í™”)
    rename_map = {}
    for col in df.columns:
        if 'ë²ˆí˜¸' in col: rename_map[col] = 'ë²ˆí˜¸'
        elif 'ì˜ì—­' in col: rename_map[col] = 'ê³¼ëª©/ì˜ì—­'
        elif 'ì‹œê°„' in col: rename_map[col] = 'ì‹œìˆ˜'
        elif 'íŠ¹ê¸°ì‚¬í•­' in col: rename_map[col] = 'ë‚´ìš©'
    
    df = df.rename(columns=rename_map)
    
    if 'ë‚´ìš©' not in df.columns or 'ê³¼ëª©/ì˜ì—­' not in df.columns: return None

    # ë°ì´í„° ì •ì œ
    df['ë²ˆí˜¸'] = pd.to_numeric(df['ë²ˆí˜¸'], errors='coerce')
    
    # 1. í—¤ë” ë°˜ë³µ ì œê±°
    df = df[df['ê³¼ëª©/ì˜ì—­'] != 'ì˜ ì—­']
    df = df[df['ê³¼ëª©/ì˜ì—­'] != 'ì˜ì—­']
    
    # 2. ê°’ ì±„ìš°ê¸° (í˜ì´ì§€ ë„˜ê¹€ ëŒ€ì‘)
    df['ë²ˆí˜¸'] = df['ë²ˆí˜¸'].ffill()
    df['ê³¼ëª©/ì˜ì—­'] = df['ê³¼ëª©/ì˜ì—­'].ffill()
    df['ì‹œìˆ˜'] = df['ì‹œìˆ˜'].ffill()
    
    # 3. ìœ íš¨í•œ ë°ì´í„° í•„í„°ë§
    df = df.dropna(subset=['ë²ˆí˜¸'])
    
    # [ì¤‘ìš”] ì§„ë¡œí™œë™ì˜ 'í¬ë§ë¶„ì•¼' í–‰ ì œê±°
    # 'ë‚´ìš©' ì»¬ëŸ¼ì— 'í¬ë§ë¶„ì•¼'ë¼ëŠ” ê¸€ìê°€ ìˆê±°ë‚˜, 'ì¡°ë¦¬ì‚¬' ì²˜ëŸ¼ ì§ì—…ëª…ë§Œ ìˆëŠ” ê²½ìš°(ë³´í†µ 5ê¸€ì ì´í•˜)ë¥¼ ì£¼ì˜í•´ì•¼ í•¨.
    # í•˜ì§€ë§Œ CSV êµ¬ì¡°ìƒ 'í¬ë§ë¶„ì•¼' ë¼ë²¨ì´ ìˆëŠ” í–‰ì€ 'ë‚´ìš©' ì»¬ëŸ¼ì— 'í¬ë§ë¶„ì•¼'ë¼ê³  ì°í˜€ìˆì„ í™•ë¥ ì´ ë†’ìŒ.
    df = df[df['ë‚´ìš©'].astype(str) != 'í¬ë§ë¶„ì•¼']
    df = df[~df['ë‚´ìš©'].astype(str).str.contains('í¬ë§ë¶„ì•¼', na=False)] # í¬ë§ë¶„ì•¼ í…ìŠ¤íŠ¸ í¬í•¨ í–‰ ì‚­ì œ
    
    # ë‚´ìš©ì´ ë¹„ì–´ìˆì§€ ì•Šì€ ê²ƒë§Œ ë‚¨ê¸°ë˜, ì§„ë¡œí™œë™ì˜ ê²½ìš° ë‚´ìš©ì´ ë‹¤ìŒ ì¤„ì— ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    # ìœ„ì—ì„œ ffillì„ í–ˆì§€ë§Œ, ë‚´ìš©ì€ ffillí•˜ë©´ ì•ˆë¨ (ì„œë¡œ ë‹¤ë¥¸ ë‚´ìš©ì´ ì„ì„).
    # ë”°ë¼ì„œ ë‚´ìš©ì€ ë¹„ì–´ìˆëŠ” í–‰ì„ ì œê±°í•´ì•¼ í•¨.
    df = df.dropna(subset=['ë‚´ìš©'])

    # 4. ë‚´ìš© ë³‘í•©
    df_grouped = df.groupby(['ë²ˆí˜¸', 'ê³¼ëª©/ì˜ì—­', 'ì‹œìˆ˜'])['ë‚´ìš©'].apply(lambda x: ' '.join(x.astype(str))).reset_index()
    
    # ìµœì¢… í¬ë§·
    df_grouped['í•™ë…„ ë°˜'] = grade_class
    df_grouped['í•™ê¸°'] = '' # ì°½ì²´ëŠ” ë³´í†µ í•™ê¸° êµ¬ë¶„ ì—†ì´ í†µë…„
    
    return df_grouped[['í•™ë…„ ë°˜', 'ë²ˆí˜¸', 'í•™ê¸°', 'ê³¼ëª©/ì˜ì—­', 'ì‹œìˆ˜', 'ë‚´ìš©']]


def detect_duplicates(df):
    """ë³µë¶™(ì¤‘ë³µ) ë¬¸ì¥ íƒì§€"""
    sentence_pattern = re.compile(r'[^.!?]+[.!?]')
    df['ì¤‘ë³µì—¬ë¶€'] = False
    df['ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)'] = ''
    
    for subject, group in df.groupby('ê³¼ëª©/ì˜ì—­'):
        if len(group) < 2: continue
        
        sentence_counts = {}
        for idx, row in group.iterrows():
            content = str(row['ë‚´ìš©'])
            sentences = [s.strip() for s in sentence_pattern.findall(content)]
            for s in sentences:
                if len(s) < 10: continue
                sentence_counts[s] = sentence_counts.get(s, 0) + 1
        
        duplicate_sentences = {s for s, count in sentence_counts.items() if count > 1}
        
        for idx, row in group.iterrows():
            content = str(row['ë‚´ìš©'])
            sentences = [s.strip() for s in sentence_pattern.findall(content)]
            found_duplicates = [s for s in sentences if s in duplicate_sentences]
            
            if found_duplicates:
                df.at[idx, 'ì¤‘ë³µì—¬ë¶€'] = True
                unique_dupes = list(set(found_duplicates))
                df.at[idx, 'ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)'] = " / ".join(unique_dupes)

    return df

def to_excel_with_style(df):
    """ì—‘ì…€ ìŠ¤íƒ€ì¼ë§ ë° ì €ì¥"""
    output = io.BytesIO()
    save_cols = [c for c in df.columns if c != 'ì¤‘ë³µì—¬ë¶€']
    
    def style_duplicate(row):
        styles = [''] * len(row)
        if row.get('ì¤‘ë³µì—¬ë¶€', False):
            try:
                content_idx = row.index.get_loc('ë‚´ìš©')
                styles[content_idx] = 'color: red; font-weight: bold;'
            except: pass
            try:
                note_idx = row.index.get_loc('ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)')
                styles[note_idx] = 'color: red;'
            except: pass
        return styles

    styler = df.style.apply(style_duplicate, axis=1)
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        styler.to_excel(writer, index=False, columns=save_cols, sheet_name='ì •ë¦¬ê²°ê³¼')
        worksheet = writer.sheets['ì •ë¦¬ê²°ê³¼']
        for idx, col in enumerate(save_cols):
            width = 50 if 'ë‚´ìš©' in col or 'ë¹„ê³ ' in col else 10
            worksheet.column_dimensions[chr(65 + idx)].width = width
            
    return output.getvalue()

# -----------------------------------------------------------------------------
# 3. ë©”ì¸ ì•± UI
# -----------------------------------------------------------------------------
st.set_page_config(page_title="ìƒê¸°ë¶€ í†µí•© ì •ë¦¬ ë§ˆë²•ì‚¬", layout="wide")

st.title("ğŸ« ìƒê¸°ë¶€ í†µí•© ì •ë¦¬ & ë³µë¶™ íƒì§€")
st.markdown("""
**ì§€ì› íŒŒì¼:** í–‰íŠ¹, ì„¸íŠ¹(êµê³¼), ì°½ì²´(ììœ¨/ì§„ë¡œ)
**ê¸°ëŠ¥:** 1. ì—‘ì…€/CSV ì—…ë¡œë“œ ì‹œ **ìë™ ë¶„ë¥˜ ë° ì •ë¦¬**
2. ì°½ì²´(ì§„ë¡œ)ì˜ **'í¬ë§ë¶„ì•¼' ìë™ ì‚­ì œ**
3. **'ì‹œìˆ˜' ì—´ ì¶”ê°€** ë° **ê³¼ëª©-ë²ˆí˜¸ ìˆœ ì •ë ¬**
4. **ë³µë¶™ ì˜ì‹¬ ë¬¸ì¥ ë¹¨ê°„ìƒ‰ í‘œì‹œ**
""")

uploaded_files = st.file_uploader(
    "ì²˜ë¦¬í•  íŒŒì¼ë“¤ì„ ëª¨ë‘ ì˜¬ë ¤ì£¼ì„¸ìš”", 
    accept_multiple_files=True,
    type=['xlsx', 'xls', 'csv']
)

if uploaded_files:
    all_results = []
    
    with st.status("íŒŒì¼ ë¶„ì„ ë° ì²˜ë¦¬ ì¤‘...", expanded=True) as status:
        for file in uploaded_files:
            df_raw = load_data(file)
            if df_raw is None:
                st.error(f"{file.name}: ì½ê¸° ì‹¤íŒ¨")
                continue
                
            grade_class = extract_grade_class(df_raw)
            file_type = detect_file_type(df_raw)
            
            processed_df = None
            type_label = ""
            
            if file_type == 'HANG':
                processed_df = process_hang(df_raw, grade_class)
                type_label = "í–‰ë™íŠ¹ì„±"
            elif file_type == 'KYO':
                processed_df = process_kyo(df_raw, grade_class)
                type_label = "ì„¸ë¶€ëŠ¥ë ¥"
            elif file_type == 'CHANG':
                processed_df = process_chang(df_raw, grade_class)
                type_label = "ì°½ì˜ì ì²´í—˜"
            else:
                st.warning(f"âš ï¸ {file.name}: ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹ (ê±´ë„ˆëœ€)")
                continue
                
            if processed_df is not None and not processed_df.empty:
                all_results.append(processed_df)
                st.write(f"âœ… {file.name} ({type_label} / {grade_class}) - {len(processed_df)}ëª… ì²˜ë¦¬")
            else:
                st.warning(f"âš ï¸ {file.name}: ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")

        status.update(label="ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!", state="complete", expanded=False)

    if all_results:
        # 1. í†µí•©
        final_df = pd.concat(all_results, ignore_index=True)
        
        # 2. ì •ë ¬ (ìš”ì²­ì‚¬í•­: ê³¼ëª©/ì˜ì—­ -> ë²ˆí˜¸ ìˆœ)
        # ì‹œìˆ˜ëŠ” ì •ë ¬ì— ì˜í–¥ ì—†ìœ¼ë‚˜ ë³´ê¸° ì¢‹ê²Œ í¬í•¨ ê°€ëŠ¥
        final_df = final_df.sort_values(by=['ê³¼ëª©/ì˜ì—­', 'ë²ˆí˜¸'])
        
        # 3. ì¤‘ë³µ ë¶„ì„
        final_df = detect_duplicates(final_df)
        
        # 4. ë¯¸ë¦¬ë³´ê¸°
        st.divider()
        st.subheader("ğŸ“Š ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        
        def highlight_row(row):
            return ['background-color: #ffe6e6' if row['ì¤‘ë³µì—¬ë¶€'] else '' for _ in row]
            
        st.dataframe(
            final_df.style.apply(highlight_row, axis=1),
            column_config={
                "ì‹œìˆ˜": st.column_config.TextColumn("ì‹œìˆ˜", width="small"),
                "ë¹„ê³ (ì¤‘ë³µë¬¸ì¥)": st.column_config.TextColumn("âš ï¸ ë³µë¶™ ì˜ì‹¬ ë¬¸ì¥", width="medium"),
                "ì¤‘ë³µì—¬ë¶€": None
            },
            use_container_width=True
        )
        
        # 5. ë‹¤ìš´ë¡œë“œ
        excel_data = to_excel_with_style(final_df)
        
        st.download_button(
            label="ğŸ“¥ í†µí•© ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (.xlsx)",
            data=excel_data,
            file_name="ìƒê¸°ë¶€_í†µí•©_ì •ë¦¬ê²°ê³¼.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.info("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
